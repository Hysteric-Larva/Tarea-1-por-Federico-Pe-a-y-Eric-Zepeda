{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 1. Aprendizaje con regresión lineal.\n",
    "\n",
    "El modelo de regresión lineal  es una combinación lineal entre variables independientes para obtener otra variable, dependiente de éstas. Lo cual puede resultar bastante simple, pero, hoy en día, ha podido ser aplicado a varios problemas con buenos resultados, como predicción en finanzas y en medicina. Sin embargo, también puede ser un medio para aplicar un modelo más grande, por ejemplo utilizarlo para que, con el resuido, detectar *outliers*, rellenar vacíos/datos incompletos o aprender un *score* para ranquear objetos, lo que haremos en esta sección.\n",
    "\n",
    "<img src=\"http://chanakya.ca/wp-content/uploads/2018/05/EstimateMultipleLinearRegressionCoefficientsExample_01.png\" height=\"15%\" />\n",
    "\n",
    "\n",
    "El problema de *learning to rank* es aplicado comúnmente en *Information Retrieval* (IR). Sin embargo, el aprender ésta función puede ser crucial para modelar la importancia de distintos objetos.  \n",
    "\n",
    "\n",
    "En esta actividad trabajaremos con el problema de predecir el *ranking* mundial de una Universidad en base a distintas características de ésta (dataset *World University Rankings*, a través del siguiente __[link](https://www.kaggle.com/mylesoneill/world-university-rankings)__) en la plataforma de *Kaggle*. En este problema el *ranking* es una medición de qué tan buena es la universidad e intentaremos predecirla a través un modelo simple de regresión lineal. En particular, dentro de los miles de diferentes sistemas de rankings, nacionales e internacionales, entre los cuales comúnmente existen desacuerdos entre ellos, trabajaremos con el ranking ampliamente considerado como uno de las más influyentes y ampliamente observadas: *Times Higher Education World University* .\n",
    "\n",
    "\n",
    "> a) Cargue los datos a analizar, descargándolos desde la plataforma como se indicó, en formato *dataframe pandas*. Descríbalos adecuadamente, ya sea la variable dependiente o las independientes, si es que lo son."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2603, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"timesData.csv\")\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teaching</th>\n",
       "      <th>research</th>\n",
       "      <th>citations</th>\n",
       "      <th>student_staff_ratio</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2603.000000</td>\n",
       "      <td>2603.000000</td>\n",
       "      <td>2603.000000</td>\n",
       "      <td>2544.000000</td>\n",
       "      <td>2603.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.801498</td>\n",
       "      <td>35.910257</td>\n",
       "      <td>60.921629</td>\n",
       "      <td>18.445283</td>\n",
       "      <td>2014.075682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>17.604218</td>\n",
       "      <td>21.254805</td>\n",
       "      <td>23.073219</td>\n",
       "      <td>11.458698</td>\n",
       "      <td>1.685733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.900000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>2011.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.700000</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>11.975000</td>\n",
       "      <td>2013.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.900000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>2014.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.400000</td>\n",
       "      <td>47.250000</td>\n",
       "      <td>79.050000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>2016.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.700000</td>\n",
       "      <td>99.400000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>162.600000</td>\n",
       "      <td>2016.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          teaching     research    citations  student_staff_ratio         year\n",
       "count  2603.000000  2603.000000  2603.000000          2544.000000  2603.000000\n",
       "mean     37.801498    35.910257    60.921629            18.445283  2014.075682\n",
       "std      17.604218    21.254805    23.073219            11.458698     1.685733\n",
       "min       9.900000     2.900000     1.200000             0.600000  2011.000000\n",
       "25%      24.700000    19.600000    45.500000            11.975000  2013.000000\n",
       "50%      33.900000    30.500000    62.500000            16.100000  2014.000000\n",
       "75%      46.400000    47.250000    79.050000            21.500000  2016.000000\n",
       "max      99.700000    99.400000   100.000000           162.600000  2016.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobre los datos:\n",
    "\n",
    "\n",
    "Consideraremos como variable dependiente el puntaje total (total_score) debido a que como se quiere caracterizar mediante un puntaje cada universidad y luego para ponerle un rango, se ordenará de manera descendente para así no utilziar la variable world_rank.\n",
    "* así consideraremos para la variable dependiente:\n",
    "    1. total_score\n",
    "* y como variables independientes:\n",
    "    1. teaching\n",
    "    2. international\n",
    "    3. research \n",
    "    4. citations\n",
    "    5. income \n",
    "    6. num_students\n",
    "    7. student_staff_ratio\n",
    "    8. international_student\n",
    "    9. female_male_ratio\n",
    "* Las variables que no se utilizarán en la regresión alineal excepto para reconocer la universisad en cuestión será:\n",
    "    1. world_rank (porque es lo mismo que  total_Score ordenado descendiente)\n",
    "    2. university_name (por ser string)\n",
    "    3. Country (por ser string)\n",
    "    4. year (Si bien el año cambia, el ranking no)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b) Debido a la estructura será necesario realizar un leve pre-proceso. Existen vacíos entre los datos o valores '-', por lo que será necesario eliminarlos (*o si piensa una mejor manera de manejar ésto puede hacerlo, se verá reflejado en su nota*). Además de ésto deje los datos con *score unkown* o '-' en un conjunto *target* separado, *unlabeled data* (éste será el objetivo del entrenamiento) ¿Cuántos datos quedan en cada conjunto? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2174, 82)\n",
      "(954, 82)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>world_rank</th>\n",
       "      <th>university_name</th>\n",
       "      <th>teaching</th>\n",
       "      <th>international</th>\n",
       "      <th>research</th>\n",
       "      <th>citations</th>\n",
       "      <th>income</th>\n",
       "      <th>total_score</th>\n",
       "      <th>num_students</th>\n",
       "      <th>student_staff_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>country_Taiwan</th>\n",
       "      <th>country_Thailand</th>\n",
       "      <th>country_Turkey</th>\n",
       "      <th>country_Uganda</th>\n",
       "      <th>country_Ukraine</th>\n",
       "      <th>country_United Arab Emirates</th>\n",
       "      <th>country_United Kingdom</th>\n",
       "      <th>country_United States of America</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>California Institute of Technology</td>\n",
       "      <td>97.7</td>\n",
       "      <td>54.6</td>\n",
       "      <td>98.0</td>\n",
       "      <td>99.9</td>\n",
       "      <td>83.7</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2243</td>\n",
       "      <td>6.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Massachusetts Institute of Technology</td>\n",
       "      <td>97.8</td>\n",
       "      <td>82.3</td>\n",
       "      <td>91.4</td>\n",
       "      <td>99.9</td>\n",
       "      <td>87.5</td>\n",
       "      <td>95.6</td>\n",
       "      <td>11074</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>98.3</td>\n",
       "      <td>29.5</td>\n",
       "      <td>98.1</td>\n",
       "      <td>99.2</td>\n",
       "      <td>64.3</td>\n",
       "      <td>94.3</td>\n",
       "      <td>15596</td>\n",
       "      <td>7.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>90.5</td>\n",
       "      <td>77.7</td>\n",
       "      <td>94.1</td>\n",
       "      <td>94.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>91.2</td>\n",
       "      <td>18812</td>\n",
       "      <td>11.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>University of Oxford</td>\n",
       "      <td>88.2</td>\n",
       "      <td>77.2</td>\n",
       "      <td>93.9</td>\n",
       "      <td>95.1</td>\n",
       "      <td>73.5</td>\n",
       "      <td>91.2</td>\n",
       "      <td>19919</td>\n",
       "      <td>11.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Imperial College London</td>\n",
       "      <td>89.2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>94.5</td>\n",
       "      <td>88.3</td>\n",
       "      <td>92.9</td>\n",
       "      <td>90.6</td>\n",
       "      <td>15060</td>\n",
       "      <td>11.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Johns Hopkins University</td>\n",
       "      <td>80.9</td>\n",
       "      <td>58.5</td>\n",
       "      <td>89.2</td>\n",
       "      <td>92.3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.4</td>\n",
       "      <td>15128</td>\n",
       "      <td>3.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Cornell University</td>\n",
       "      <td>82.2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>88.8</td>\n",
       "      <td>88.1</td>\n",
       "      <td>34.7</td>\n",
       "      <td>83.9</td>\n",
       "      <td>21424</td>\n",
       "      <td>10.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>University of Michigan</td>\n",
       "      <td>83.9</td>\n",
       "      <td>53.3</td>\n",
       "      <td>89.1</td>\n",
       "      <td>84.1</td>\n",
       "      <td>59.6</td>\n",
       "      <td>83.4</td>\n",
       "      <td>41786</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>University of Pennsylvania</td>\n",
       "      <td>71.8</td>\n",
       "      <td>32.9</td>\n",
       "      <td>82.7</td>\n",
       "      <td>93.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>79.5</td>\n",
       "      <td>20376</td>\n",
       "      <td>6.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   world_rank                        university_name  teaching international  \\\n",
       "1           2     California Institute of Technology      97.7          54.6   \n",
       "2           3  Massachusetts Institute of Technology      97.8          82.3   \n",
       "3           4                    Stanford University      98.3          29.5   \n",
       "5           6                University of Cambridge      90.5          77.7   \n",
       "6           6                   University of Oxford      88.2          77.2   \n",
       "8           9                Imperial College London      89.2          90.0   \n",
       "12         13               Johns Hopkins University      80.9          58.5   \n",
       "13         14                     Cornell University      82.2          62.4   \n",
       "15         15                 University of Michigan      83.9          53.3   \n",
       "18         19             University of Pennsylvania      71.8          32.9   \n",
       "\n",
       "    research  citations income total_score  num_students  student_staff_ratio  \\\n",
       "1       98.0       99.9   83.7        96.0          2243                  6.9   \n",
       "2       91.4       99.9   87.5        95.6         11074                  9.0   \n",
       "3       98.1       99.2   64.3        94.3         15596                  7.8   \n",
       "5       94.1       94.0   57.0        91.2         18812                 11.8   \n",
       "6       93.9       95.1   73.5        91.2         19919                 11.6   \n",
       "8       94.5       88.3   92.9        90.6         15060                 11.7   \n",
       "12      89.2       92.3  100.0        86.4         15128                  3.6   \n",
       "13      88.8       88.1   34.7        83.9         21424                 10.2   \n",
       "15      89.1       84.1   59.6        83.4         41786                  9.0   \n",
       "18      82.7       93.6   43.7        79.5         20376                  6.5   \n",
       "\n",
       "    ...   country_Taiwan  country_Thailand  country_Turkey  country_Uganda  \\\n",
       "1   ...                0                 0               0               0   \n",
       "2   ...                0                 0               0               0   \n",
       "3   ...                0                 0               0               0   \n",
       "5   ...                0                 0               0               0   \n",
       "6   ...                0                 0               0               0   \n",
       "8   ...                0                 0               0               0   \n",
       "12  ...                0                 0               0               0   \n",
       "13  ...                0                 0               0               0   \n",
       "15  ...                0                 0               0               0   \n",
       "18  ...                0                 0               0               0   \n",
       "\n",
       "    country_Ukraine  country_United Arab Emirates  country_United Kingdom  \\\n",
       "1                 0                             0                       0   \n",
       "2                 0                             0                       0   \n",
       "3                 0                             0                       0   \n",
       "5                 0                             0                       1   \n",
       "6                 0                             0                       1   \n",
       "8                 0                             0                       1   \n",
       "12                0                             0                       0   \n",
       "13                0                             0                       0   \n",
       "15                0                             0                       0   \n",
       "18                0                             0                       0   \n",
       "\n",
       "    country_United States of America  female  male  \n",
       "1                                  1      33    67  \n",
       "2                                  1      37    63  \n",
       "3                                  1      42    58  \n",
       "5                                  0      46    54  \n",
       "6                                  0      46    54  \n",
       "8                                  0      37    63  \n",
       "12                                 1      50    50  \n",
       "13                                 1      48    52  \n",
       "15                                 1      48    52  \n",
       "18                                 1      51    49  \n",
       "\n",
       "[10 rows x 82 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convertToInt(x):\n",
    "    try:\n",
    "        x = int(x)\n",
    "    except:\n",
    "        x = 0\n",
    "    return x\n",
    "df.dropna(axis=0,inplace=True,how='any') #borra nan\n",
    "df[\"total_score\"] = df[\"total_score\"].apply(lambda x: x.replace('-','unknown')) #rellena \n",
    "df = df[~(df == '-').any(axis=1)] #elimina filas con valores nulos\n",
    "\n",
    "nuevo_df  = pd.get_dummies(df, columns=[\"country\"]) #column to categorical\n",
    "\n",
    "nuevo_df['female'] = nuevo_df['female_male_ratio'].str.split(':', expand=True)[0].apply(convertToInt)\n",
    "nuevo_df['male'] = nuevo_df['female_male_ratio'].str.split(':', expand=True)[1].apply(convertToInt)\n",
    "nuevo_df['female_male_ratio'] =  np.where(nuevo_df['male'] == 0, 0, nuevo_df['female']/nuevo_df['male']) #si no hay (rellena 0) \n",
    "nuevo_df['num_students'] = nuevo_df['num_students'].apply(lambda x: int(str(x).replace(',','')))\n",
    "nuevo_df['international_students'] = nuevo_df['international_students'].apply(lambda x: int(str(x).replace('%','')))\n",
    "nuevo_df['student_staff_ratio'] = df['student_staff_ratio']\n",
    "print(nuevo_df.shape)\n",
    "\n",
    "df_test = nuevo_df[nuevo_df[\"total_score\"]=='unknown']  #para predecir al final\n",
    "nuevo_df =  nuevo_df[nuevo_df[\"total_score\"]!='unknown'] #elimina unknown rank..\n",
    "print(nuevo_df.shape)\n",
    "nuevo_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el  pre-procesamiento de datos se consideraron dos métodos para limpiar las filas que posean un dato atipico respecto a lo que se espera. Esto fue:\n",
    "\n",
    "\n",
    "A. Mediante la forma establecida:\n",
    "    1. Se elimina cada entrada nula\n",
    "    2. cada entrada que posea un \"-\" se cambia por el valor \"unknown\"\n",
    "    3. se categoriza cada pais transformandolos en una columna que posee un valor binario según corresponda.\n",
    "    4. las entradas que tengan el valor \"unknown\" de la columna \"total score\" es nuestro valor que queremos obtener. (datos de prueba).\n",
    "    5. female_male_ratio se separa mediante un split para tener las proporciones en cantidades enteras.\n",
    "    \n",
    "    * la tabla se redujo de (2174, 82) a (954, 82), es decir, ¡se eliminaron 1220 filas!\n",
    "    \n",
    "B. Mediante nuestra propuesta:\n",
    "\n",
    "            En Machine Learning la información es muy importante al momento de generar un entrenamiento y si  más aún cuando se eliminan 1220 filas por lo que mediante esta propuesta se buscará obtener un valor cercano al que se pretende para tener más información en nuestro entrenamiento que afecte poco al desarrollo de nuestra regresión lineal siguiendo los siguientes pasos:\n",
    "            1. Sea n la posicion de la fila que falta, llamaremos filas vecinas a n-1 y n+1.\n",
    "            2. respecto a los vecinos más cercanos al igual que en piecewise interpolation se calcula el punto medio entre las dos variables considerando un reescale dependiendo de la diferencia entre el total score para reducir el lugar de posibilidades para donde se encontrará el punto que intentamos hallar.\n",
    "            3. A través de la diferencia del error se obtendrá un intervalo de confianza sobre el cual estará el valor más cercano al faltante\n",
    "            4. se buscará el vecino más cercano para definir el único signo a considerar.\n",
    "            5. sobre dicho intervalo se aplicará una función random para obtener nuestro valor.\n",
    "            \n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\n",
       "          $$\\frac{x_{n-1} + x_{x+1}}{2}\\big(1 + (Y_{n-1} - Y_{n+1} - 0.1)\\big) \\rightarrow \\bar{x}$$  \n",
       "    $$Error_{low} = \\sum_{n=0}^{n=8}min\\{|x_{n} - x_{n+1}|, |x_{n} - x_{n+1}|\\}$$\n",
       "    $$Error_{high}\\sum_{n=0}^{n=8}max\\{|x_{n} - x_{n+1}|, |x_{n} - x_{n+1}|\\}$$\n",
       "    calculamos el intervalo de confianza como:\n",
       "        $$\\bar{E} = \\frac{Error_{low}}{Error_{high}}$$\n",
       "        $$\\Delta = \\bar{x}\\cdot \\bar{E}$$\n",
       "        $$\\delta = sign\\cdot \\bar{x}\\cdot \\bar{E}$$\n",
       "        $$\\bar{x} \\rightarrow \\bar{x} + \\delta \\pm \\Delta$$\n",
       "        \n",
       "        Finalmente, nuestro dato faltante pertenecerá a dicho intervalo de confianza, pero para reducir el error, se considerará una traslacion al vecino más cercano\n",
       "        \n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\n",
    "          $$\\frac{x_{n-1} + x_{x+1}}{2}\\big(1 + (Y_{n-1} - Y_{n+1} - 0.1)\\big) \\rightarrow \\bar{x}$$  \n",
    "    $$Error_{low} = \\sum_{n=0}^{n=8}min\\{|x_{n} - x_{n+1}|, |x_{n} - x_{n+1}|\\}$$\n",
    "    $$Error_{high}\\sum_{n=0}^{n=8}max\\{|x_{n} - x_{n+1}|, |x_{n} - x_{n+1}|\\}$$\n",
    "    calculamos el intervalo de confianza como:\n",
    "        $$\\bar{E} = \\frac{Error_{low}}{Error_{high}}$$\n",
    "        $$\\Delta = \\bar{x}\\cdot \\bar{E}$$\n",
    "        $$\\delta = sign\\cdot \\bar{x}\\cdot \\bar{E}$$\n",
    "        $$\\bar{x} \\rightarrow \\bar{x} + \\delta \\pm \\Delta$$\n",
    "        \n",
    "        Finalmente, nuestro dato faltante pertenecerá a dicho intervalo de confianza, pero para reducir el error, se considerará una traslacion al vecino más cercano\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c) Cree las matrices de cada conjunto con las que trabajará. Además de ésto separe el conjunto de pruebas fijo que se utilizará, recuerde que éste no puede ser utilizado. Si estima conveniente también cree conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(954, 79)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = nuevo_df['total_score'].values\n",
    "X = nuevo_df.drop([\"total_score\",\"world_rank\",\"university_name\"],axis=1).values\n",
    "X_test = df_test.drop([\"total_score\",\"world_rank\",\"university_name\"],axis=1).values\n",
    "Y = Y.astype('float32')\n",
    "X = X.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "validation_set = Y #if you want to create val!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">d) Normalice los datos antes de trabajar. Explique la importancia/conveniencia de realizar ésto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-745507177ee5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mX_val_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mX_test_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_val' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> e) Realice una regresión lineal de mı́nimos cuadrados básica. Mida el residuo de cada predicción en cada dato y haga un gráfico de éste ¿Qué indica lo observado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as LR\n",
    "linreg = LR(fit_intercept=True, n_jobs=1)\n",
    "linreg.fit(X_train_scaled,y_train)\n",
    "...\n",
    "import seaborn as sns\n",
    "res = y_train-linreg.predict(X_train_scaled)\n",
    "sns.distplot(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> f) Construya una tabla con los pesos, Z-score y F-score correspondientes a cada predictor (variable), compare estos valores. ¿Qué sucede si hacemos un raking de los atributos en base al peso obtenido en la regresión? Compare y comente ¿Qué variables están más correlacionadas con la respuesta? Si usáramos un nivel de significación del 5%. ¿Qué es lo que observa y cuál puede ser la causa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> g) Calcule la información mútua de los distintos predictores (variables) con respecto a la variable *output* o *target*. Comente con lo calculado anteriormente y si le parece razonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-5d6e213795c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmutual_info_regression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mminfo_predictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmutual_info_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "minfo_predictor = mutual_info_regression(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> h)  Construya una función que implemente *Forward Step-wise Selection* (FSS). Es decir, partiendo con un modelo sin predictores (variables), agregue un predictor a la vez, re-ajustando el modelo de regresión en cada paso. Para seleccionar localmente una variable, proponga/implemente un criterio distinto al utilizado en el código de ejemplo. Construya un gráfico que muestre el error de entrenamiento y el error de pruebas como función del número de variables en el modelo. Ordene el eje $x$ de menor a mayor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> i) Ajuste un modelo lineal utilizando “*Ridge Regression*”, es decir, regularizando con la norma $l_2$. Utilice valores del parámetro de regularización $\\lambda$ en el rango [$10^0, 10^6$], variando si estima conveniente. Construya un gráfico que muestre los coeficientes obtenidos como función del parámetro de regularización. Deje un gráfico sólo para analizar los coeficientes de los países. Describa lo que observa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> j) Ajuste un modelo lineal utilizando el método “*Lasso*”, es decir, regularizando con la norma $l_1$. Utilice valores del parámetro de regularización $\\lambda$ en el rango [$10^{-2},10^3$]. Para obtener el código, modifique el ejemplo anterior. Construya un gráfico que muestre los coeficientes obtenidos como función del parámetro de regularización. Describa lo que observa. ¿Es más efectivo *Lasso* para seleccionar atributos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> k) Escogiendo uno de los dos métodos regularizadores anteriores, especificando el porqué, construya un gráfico que muestre el error de entrenamiento y el de pruebas como función del parámetro de regularización. Discuta lo que  observa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> l) Estime el valor del parámetro de regularización en **alguno** de los modelos anteriores haciendo uso de la técnica validación cruzada con un número de folds igual a $K= 5$ y $K = 10$. Recuerde que para que la estimación sea razonable, en cada configuración (*fold*) deberá reajustar los pesos del modelo. Mida el error real del modelo (ésto es sobre el conjunto de pruebas). Debido a la escala del error puede utilizar auxiliarmente *MAE* como métrica de desempeño. Compare y concluya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
